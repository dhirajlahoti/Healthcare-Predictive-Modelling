{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pydotplus\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "data = pd.read_csv(\"C:/Users/12408/Desktop/INST737/balanced_data.csv\")\n",
    "# Generate a random permutation of indices\n",
    "indices = np.random.permutation(len(data))\n",
    "# Specify the ratio for splitting\n",
    "train_ratio = 0.8\n",
    "test_ratio = 1 - train_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of samples for training and testing\n",
    "num_train_samples = int(train_ratio * len(data))\n",
    "num_test_samples = len(data) - num_train_samples\n",
    "\n",
    "# Use the shuffled indices to split the dataset\n",
    "train_indices = indices[:num_train_samples]\n",
    "test_indices = indices[num_train_samples:]\n",
    "\n",
    "# Create training and testing datasets\n",
    "train_data = data.iloc[train_indices]\n",
    "test_data = data.iloc[test_indices]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Distribution:\n",
      "0    0.333333\n",
      "1    0.333333\n",
      "2    0.333333\n",
      "Name: Diabetes, dtype: float64\n",
      "Training Set Distribution:\n",
      "1    0.340267\n",
      "0    0.333687\n",
      "2    0.326045\n",
      "Name: Diabetes, dtype: float64\n",
      "Testing Set Distribution:\n",
      "2    0.362479\n",
      "0    0.331919\n",
      "1    0.305603\n",
      "Name: Diabetes, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution of 'Diabetes' in the original dataset\n",
    "original_distribution = data['Diabetes'].value_counts(normalize=True)\n",
    "\n",
    "# Check the distribution of 'Diabetes' in the training dataset\n",
    "train_distribution = train_data['Diabetes'].value_counts(normalize=True)\n",
    "\n",
    "# Check the distribution of 'Diabetes' in the testing dataset\n",
    "test_distribution = test_data['Diabetes'].value_counts(normalize=True)\n",
    "\n",
    "print(\"Original Distribution:\")\n",
    "print(original_distribution)\n",
    "\n",
    "print(\"Training Set Distribution:\")\n",
    "print(train_distribution)\n",
    "\n",
    "print(\"Testing Set Distribution:\")\n",
    "print(test_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Diabetes', axis=1)\n",
    "y = data['Diabetes']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=7)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=7)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=7)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=7)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Training):\n",
      "[[932 359 255]\n",
      " [254 733 595]\n",
      " [173 418 992]]\n",
      "Confusion Matrix (Testing):\n",
      "[[205 126  86]\n",
      " [ 69 150 162]\n",
      " [ 45 132 203]]\n"
     ]
    }
   ],
   "source": [
    "# Predict on the training dataset\n",
    "y_train_pred = clf.predict(X_train)\n",
    "confusion_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "\n",
    "# Predict on the testing dataset\n",
    "y_test_pred = clf.predict(X_test)\n",
    "confusion_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(\"Confusion Matrix (Training):\")\n",
    "print(confusion_matrix_train)\n",
    "print(\"Confusion Matrix (Testing):\")\n",
    "print(confusion_matrix_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Training): 56.40%\n",
      "Accuracy (Testing): 47.37%\n",
      "Classification Report (Training):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " No Diabetes       0.69      0.60      0.64      1546\n",
      "Pre-Diabetes       0.49      0.46      0.47      1582\n",
      "    Diabetes       0.54      0.63      0.58      1583\n",
      "\n",
      "    accuracy                           0.56      4711\n",
      "   macro avg       0.57      0.56      0.57      4711\n",
      "weighted avg       0.57      0.56      0.56      4711\n",
      "\n",
      "Classification Report (Testing):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " No Diabetes       0.64      0.49      0.56       417\n",
      "Pre-Diabetes       0.37      0.39      0.38       381\n",
      "    Diabetes       0.45      0.53      0.49       380\n",
      "\n",
      "    accuracy                           0.47      1178\n",
      "   macro avg       0.49      0.47      0.48      1178\n",
      "weighted avg       0.49      0.47      0.48      1178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy for training and testing\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Accuracy (Training): {:.2f}%\".format(accuracy_train * 100))\n",
    "print(\"Accuracy (Testing): {:.2f}%\".format(accuracy_test * 100))\n",
    "\n",
    "# Display the classification report\n",
    "classification_report_train = classification_report(y_train, y_train_pred, target_names=[\"No Diabetes\", \"Pre-Diabetes\", \"Diabetes\"])\n",
    "classification_report_test = classification_report(y_test, y_test_pred, target_names=[\"No Diabetes\", \"Pre-Diabetes\", \"Diabetes\"])\n",
    "\n",
    "print(\"Classification Report (Training):\\n\", classification_report_train)\n",
    "print(\"Classification Report (Testing):\\n\", classification_report_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "                 Feature  Importance\n",
      "9         General_health    0.260761\n",
      "2                    BMI    0.244747\n",
      "1                    Age    0.229568\n",
      "10       Income_category    0.083379\n",
      "14      Alcohol_consumed    0.051703\n",
      "7          Average_drink    0.029638\n",
      "6          Food_shortage    0.020608\n",
      "13  HeartDiseaseorAttack    0.017109\n",
      "0                    Sex    0.016997\n",
      "4                 Smoker    0.016362\n",
      "3               COVIDPOS    0.012840\n",
      "12    Walking_difficulty    0.010451\n",
      "5      Physical_activity    0.003688\n",
      "8               MEDCOST1    0.002150\n",
      "11                Stroke    0.000000\n"
     ]
    }
   ],
   "source": [
    "feature_importances = clf.feature_importances_\n",
    "\n",
    "# Create a DataFrame to display feature importances\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display feature importances\n",
    "print(\"Feature Importances:\")\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Training) with Selected Features:\n",
      "[[1014  304  228]\n",
      " [ 338  786  458]\n",
      " [ 216  534  833]]\n",
      "Confusion Matrix (Testing) with Selected Features:\n",
      "[[223 109  85]\n",
      " [ 96 163 122]\n",
      " [ 55 156 169]]\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "selected_features = feature_importance_df.head(k)['Feature'].tolist()\n",
    "\n",
    "# Subset the data with selected features\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "# Refit the classifier with selected features\n",
    "clf.fit(X_train_selected, y_train)\n",
    "\n",
    "# Predict on the training dataset with selected features\n",
    "y_train_pred_new = clf.predict(X_train_selected)\n",
    "confusion_matrix_train = confusion_matrix(y_train, y_train_pred_new)\n",
    "\n",
    "# Predict on the testing dataset with selected features\n",
    "y_test_pred_new = clf.predict(X_test_selected)\n",
    "confusion_matrix_test = confusion_matrix(y_test, y_test_pred_new)\n",
    "\n",
    "print(\"Confusion Matrix (Training) with Selected Features:\")\n",
    "print(confusion_matrix_train)\n",
    "print(\"Confusion Matrix (Testing) with Selected Features:\")\n",
    "print(confusion_matrix_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Training): 55.89%\n",
      "Accuracy (Testing): 47.11%\n",
      "Classification Report (Training):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " No Diabetes       0.65      0.66      0.65      1546\n",
      "Pre-Diabetes       0.48      0.50      0.49      1582\n",
      "    Diabetes       0.55      0.53      0.54      1583\n",
      "\n",
      "    accuracy                           0.56      4711\n",
      "   macro avg       0.56      0.56      0.56      4711\n",
      "weighted avg       0.56      0.56      0.56      4711\n",
      "\n",
      "Classification Report (Testing):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " No Diabetes       0.60      0.53      0.56       417\n",
      "Pre-Diabetes       0.38      0.43      0.40       381\n",
      "    Diabetes       0.45      0.44      0.45       380\n",
      "\n",
      "    accuracy                           0.47      1178\n",
      "   macro avg       0.48      0.47      0.47      1178\n",
      "weighted avg       0.48      0.47      0.47      1178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy for training and testing\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred_new)\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred_new)\n",
    "\n",
    "print(\"Accuracy (Training): {:.2f}%\".format(accuracy_train * 100))\n",
    "print(\"Accuracy (Testing): {:.2f}%\".format(accuracy_test * 100))\n",
    "\n",
    "# Display the classification report\n",
    "classification_report_train = classification_report(y_train, y_train_pred_new, target_names=[\"No Diabetes\", \"Pre-Diabetes\", \"Diabetes\"])\n",
    "classification_report_test = classification_report(y_test, y_test_pred_new, target_names=[\"No Diabetes\", \"Pre-Diabetes\", \"Diabetes\"])\n",
    "\n",
    "print(\"Classification Report (Training):\\n\", classification_report_train)\n",
    "print(\"Classification Report (Testing):\\n\", classification_report_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
